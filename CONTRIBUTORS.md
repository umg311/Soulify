# Contributors

This file lists the contributors to the Soulify project and acknowledges their specific contributions.

## Core Team

- umg311 - Project lead, Flask backend architecture, SQLAlchemy database design, frontend development, UI/UX design, OpenAI API integration, DevOps
- AEdebug - Facial detection functionality development using machine learning and real time mental health advice using openAI API.
- 1x8f - Breathing/balloon game development

## Contributions Breakdown

### umg311
- Led overall project development, system design, and technical architecture
- Designed and implemented all responsive frontend interfaces and menus using HTML5, CSS3, and JavaScript
- Built the complete Flask backend architecture including RESTful API endpoints and routing system
- Designed optimized SQLAlchemy database models with proper relationships and indexing
- Implemented secure user authentication system with password hashing and session management
- Created sophisticated AI chat functionality with OpenAI API integration and context management
- Engineered prompt system for natural language understanding and therapeutic responses
- Developed intelligent topic detection and conversation management algorithms
- Designed and implemented the journal system with mood tracking and analytical features
- Integrated facial detection module into the webapp with smooth data flow between components
- Implemented secure data handling practices and user privacy protections
- Optimized application performance and response times
- Handled full project deployment, configuration management, and maintenance
- Created comprehensive documentation and user guides
- Implemented error handling and logging systems throughout the application
- Designed and executed testing protocols for all major system components

### AEdebug
- Developed the facial detection algorithm using face-api.js (TensorFlow.js-based)
- Implemented emotion classification functionality (happiness, sadness, anger, etc.)
- Created real-time video processing with HTML5 Canvas
- Built UI logic using Vanilla JavaScript
- Implemented local processing system requiring no cloud API
- Developed face bounding box with confidence scoring
- Optimized model loading times for the TinyFaceDetector model
- Achieved smooth FPS with requestAnimationFrame
- Solved coordinate mapping between video feed and canvas overlay
- Implemented confidence thresholding
- AI-Powered Help used OpenAIâ€™s API to generate real-time, conversational mental health support, offering coping strategies and resources.
- Secondary Feature Analysis: Detected mouth openness (surprise), eye aspect ratio (crying).
- Movement Tracking: Used facial landmark displacement to detect repetitive gestures (e.g., face rubbing) as signs of distress.
- UI/UX Innovations: Visual Emotion Tags: Sorted emotions alphabetically in a scrollable horizontal list, with dominant emotion highlighted. Progress Bar: Showed real-time feedback for model loading, camera activation, and analysis stages. Non-Intrusive Advice: 
  Preserved advice box visibility even when no face was detected to guide users.
- Movement Tracking: Used facial landmark displacement to detect repetitive gestures (e.g., face rubbing) as signs of distress.

### 1x8f
- Developed the interactive breathing/balloon game using JavaScript and HTML5 Canvas
- Implemented real-time breath tracking with adaptive difficulty logic
- Created smooth canvas animations with physics-based balloon expansion
- Optimized rendering with requestAnimationFrame for high FPS

## Academic Information

This project was developed by high school students from The Internation School of Choueifat - DIP

## Contact Information

For academic or professional inquiries about our work on this project:
- umar1206@gmail.com - Project lead and main developer
